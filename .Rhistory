if(cleanedDataset$Units.Sold[i] > bins$brks[3]){
rating = "H"
}
unitsSoldType <- append(unitsSoldType, rating)
}
cleanedDataset$Units.Sold.Type <- unitsSoldType
# Inspect new categorical column
str(cleanedDataset$Units.Sold.Type)
# Inspect new categorical column
summary(cleanedDataset$Units.Sold.Type)
# Inspect new categorical column
levels(cleanedDataset$Units.Sold.Type)
# Inspect new categorical column
cleanedDataset$Units.Sold.Type <- as.factor(cleanedDataset$Units.Sold.Type)
levels(cleanedDataset$Units.Sold.Type)
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- cleanedDataset$Ship.Date - cleanedDataset$Order.Date
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
cleanedDataset$Ship.Time <- deliveryDays
cleanedDataset$Ship.Time
cleanedDataset <- read.csv("./output/sales-data_cleaned.csv", stringsAsFactors = T)
cleanedDataset$Unit.Price <- ((cleanedDataset$Unit.Price - min(cleanedDataset$Unit.Price))/(max(cleanedDataset$Unit.Price) - min(cleanedDataset$Unit.Price))) * (10-1) + 1
# Discretization of Quantity (also addresses outliers)
#
# Key:
# L  -> Low
# M  -> Medium
# H  -> High
#
bins <- classIntervals(cleanedDataset$Units.Sold, 3, style = 'equal')
unitsSoldType = c()
for (i in 1:length(cleanedDataset$Units.Sold)) {
rating = "L"
if(cleanedDataset$Units.Sold[i] > bins$brks[2] && cleanedDataset$Units.Sold[i] <= bins$brks[3]){
rating = "M"
}
if(cleanedDataset$Units.Sold[i] > bins$brks[3]){
rating = "H"
}
unitsSoldType <- append(unitsSoldType, rating)
}
cleanedDataset$Units.Sold.Type <- as.factor(unitsSoldType)
# Inspect new categorical column
levels(cleanedDataset$Units.Sold.Type)
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- cleanedDataset$Ship.Date - cleanedDataset$Order.Date
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
cleanedDataset$Ship.Time <- deliveryDays
cleanedDataset <- read.csv("./output/sales-data_cleaned.csv", stringsAsFactors = T)
cleanedDataset$Unit.Price <- ((cleanedDataset$Unit.Price - min(cleanedDataset$Unit.Price))/(max(cleanedDataset$Unit.Price) - min(cleanedDataset$Unit.Price))) * (10-1) + 1
# Discretization of Quantity (also addresses outliers)
#
# Key:
# L  -> Low
# M  -> Medium
# H  -> High
#
bins <- classIntervals(cleanedDataset$Units.Sold, 3, style = 'equal')
unitsSoldType = c()
for (i in 1:length(cleanedDataset$Units.Sold)) {
rating = "L"
if(cleanedDataset$Units.Sold[i] > bins$brks[2] && cleanedDataset$Units.Sold[i] <= bins$brks[3]){
rating = "M"
}
if(cleanedDataset$Units.Sold[i] > bins$brks[3]){
rating = "H"
}
unitsSoldType <- append(unitsSoldType, rating)
}
cleanedDataset$Units.Sold.Type <- as.factor(unitsSoldType)
# Inspect new categorical column
levels(cleanedDataset$Units.Sold.Type)
# Inspect new categorical column
summary(cleanedDataset$Units.Sold.Type)
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- cleanedDataset$Ship.Date - cleanedDataset$Order.Date
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
summary(deliveryDays)
cleanedDataset$Ship.Date
cleanedDataset$Ship.Date - cleanedDataset$Order.Date
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- cleanedDataset$Ship.Date[i] - cleanedDataset$Order.Date[i]
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
summary(deliveryDays)
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- as.Date(cleanedDataset$Ship.Date[i]) - as.Date(cleanedDataset$Order.Date[i])
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
summary(deliveryDays)
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- as.Date(cleanedDataset$Ship.Date[i]) - as.Date(cleanedDataset$Order.Date[i])
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
summary(deliveryDays)
# Assigning to new column called "Ship Time"
cleanedDataset$Ship.Time <- deliveryDays
View(dataset)
# Assigning to new column called "Ship Time"
cleanedDataset$Ship.Time <- deliveryDays
View(dataset)
View(cleanedDataset)
library(classInt)
rm(list=ls())
options(scipen=99999)
# Setting working directory dynamically
tryCatch({
setwd(getSrcDirectory()[1])
}, error = function (e) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
})
# Loading dataset
dataset <- read.csv("./dataset/SalesData.csv", na.strings = c("", " ", "\"\"", "?", "??", "???", "!"), stringsAsFactors = T)
str(dataset)
summary(dataset)
# #############
# Data Cleaning
#
# Step 1 - Removal of irrelevant data
# Step 2 - Deduplicate / Aggregate data
# Step 3 - Fix structural errors
# Step 4 - Deal with missing data
# Step 5 - Filter out data outliers
# Step 6 -  Validate data
#
# NA values for Region identified using Summary
Summary(dataset$Region)
# Remove NA's from Region column
dataset$Region <- as.character(dataset$Region)
dataset$Region[is.na(dataset$Region)] <- "Unknown"
dataset$Region <- factor(dataset$Region)
# NA values for ItemType identified using Summary
Summary(dataset$ItemType)
# Remove NA's from ItemType column
dataset$ItemType <- as.character(dataset$ItemType)
dataset$ItemType[is.na(dataset$ItemType)] <- "Unknown"
dataset$ItemType <- factor(dataset$ItemType)
# NA values for Sales.Channel identified using Summary
Summary(dataset$Sales.Channel)
# Remove NA's and irrelevant values from SalesChannel column
dataset$Sales.Channel <- as.character(dataset$Sales.Channel)
dataset$Sales.Channel[is.na(dataset$Sales.Channel)] <- "Unknown"
dataset$Sales.Channel[dataset$Sales.Channel != "Online" & dataset$Sales.Channel != "Offline"] <- "Unknown"
dataset$Sales.Channel <- factor(dataset$Sales.Channel)
levels(dataset$Sales.Channel)
dataset$Order.Date <- as.Date(dataset$Order.Date, format = "%m/%d/%Y")
dataset$Ship.Date <- as.Date(dataset$Ship.Date, format = "%m/%d/%Y")
dataset$Unit.Price <- ((dataset$Unit.Price - min(dataset$Unit.Price))/(max(dataset$Unit.Price) - min(dataset$Unit.Price))) * (10-1) + 1
# Discretization of Quantity (also addresses outliers)
#
# Key:
# L  -> Low
# M  -> Medium
# H  -> High
#
bins <- classIntervals(dataset$Units.Sold, 3, style = 'equal')
unitsSoldType = c()
for (i in 1:length(dataset$Units.Sold)) {
rating = "L"
if(dataset$Units.Sold[i] > bins$brks[2] && dataset$Units.Sold[i] <= bins$brks[3]){
rating = "M"
}
if(dataset$Units.Sold[i] > bins$brks[3]){
rating = "H"
}
unitsSoldType <- append(unitsSoldType, rating)
}
dataset$Units.Sold.Type <- as.factor(unitsSoldType)
# Inspect new categorical column
summary(cleanedDataset$Units.Sold.Type)
str(dataset$Unit.Price)
hist(dataset$Unit.Price)
# Plot density graph...
plot(density(dataset$Unit.Price, na.rm = T))
# Write cleaned dataset to file
write.csv(dataset, "./output/sales-data_cleaned.csv", row.names = F)
############# DATA CLEANING COMPLETE #############
# Inspect cleaned dataset
View(dataset)
cleanedDataset <- read.csv("./output/sales-data_cleaned.csv", stringsAsFactors = T)
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- as.Date(cleanedDataset$Ship.Date[i]) - as.Date(cleanedDataset$Order.Date[i])
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
# Assigning to new column called "Ship Time"
cleanedDataset$Ship.Time <- deliveryDays
View(cleanedDataset)
# Convert factors to numeric for clustering
cleanedDataset$Order.ID <- NULL
cleanedDataset$Region <- as.numeric(cleanedDataset$Region)
cleanedDataset$Units.Sold <- as.numeric(cleanedDataset$Units.Sold)
cleanedDataset$Unit.Price <- as.numeric(cleanedDataset$Unit.Price)
cleanedDataset$Order.Priority <- as.numeric(cleanedDataset$Order.Priority)
cleanedDataset$ItemType <- as.numeric(cleanedDataset$cleanedDataset$ItemType)
cleanedDataset$ItemType <- as.numeric(cleanedDataset$cleanedDataset$ItemType)
cleanedDataset$Order.Date <- as.numeric(cleanedDataset$cleanedDataset$Order.Date)
cleanedDataset$Units.Sold.Type <- as.numeric(cleanedDataset$cleanedDataset$Units.Sold.Type)
View(dataset)
View(cleanedDataset)
cleanedDataset$ItemType <- as.numeric(cleanedDataset$cleanedDataset$ItemType)
cleanedDataset$ItemType <- as.numeric(cleanedDataset$ItemType)
cleanedDataset$Order.Date <- as.numeric(cleanedDataset$Order.Date)
cleanedDataset$Units.Sold.Type <- as.numeric(cleanedDataset$Units.Sold.Type)
View(cleanedDataset)
# Convert factors to numeric for clustering
cleanedDataset$Order.ID <- NULL
cleanedDataset$Region <- as.numeric(cleanedDataset$Region)
cleanedDataset$Units.Sold <- as.numeric(cleanedDataset$Units.Sold)
cleanedDataset$Unit.Price <- as.numeric(cleanedDataset$Unit.Price)
cleanedDataset$Order.Priority <- as.numeric(cleanedDataset$Order.Priority)
cleanedDataset$ItemType <- as.numeric(cleanedDataset$ItemType)
cleanedDataset$Order.Date <- as.numeric(cleanedDataset$Order.Date)
cleanedDataset$Units.Sold.Type <- as.numeric(cleanedDataset$Units.Sold.Type)
cleanedDataset$Sales.Channel <- as.numeric(cleanedDataset$Sales.Channel)
View(cleanedDataset)
cleanedDataset$Region <- as.numeric(cleanedDataset$Region)
cleanedDataset$Units.Sold <- as.numeric(cleanedDataset$Units.Sold)
cleanedDataset$Unit.Price <- as.numeric(cleanedDataset$Unit.Price)
cleanedDataset$Order.Priority <- as.numeric(cleanedDataset$Order.Priority)
cleanedDataset$ItemType <- as.numeric(cleanedDataset$ItemType)
cleanedDataset$Order.Date <- as.numeric(cleanedDataset$Order.Date)
cleanedDataset$Units.Sold.Type <- as.numeric(cleanedDataset$Units.Sold.Type)
cleanedDataset$Ship.Time <- as.numeric(cleanedDataset$Ship.Time)
cleanedDataset$Sales.Channel <- as.numeric(cleanedDataset$Sales.Channel)
View(cleanedDataset)
cleanedDataset[1]
for(i in 1:length(cleanedDataset)){
cleanedDataset[i] <- as.numeric(cleanedDataset)
}
for(i in 1:length(cleanedDataset)){
cleanedDataset[i] <- as.numeric(cleanedDataset[i])
}
length(cleanedDataset)
cleanedDataset["Region"]
for(i in 1:length(cleanedDataset)){
cleanedDataset[cleanedDataset[i]] <- as.numeric(cleanedDataset[i])
}
as.numeric(cleanedDataset$Order.Priority}
as.numeric(cleanedDataset$Order.Priority)
as.numeric(cleanedDataset)
cleanedDataset
as.numeric(cleanedDataset)
dplyr::mutate_all(cleanedDataset, function(x) as.numeric(x))
dplyr::mutate_all(cleanedDataset, function(x) as.numeric(x))
kmeans(cleanedDataset, 3)
kmeans(cleanedDataset[1:12,], 3)
kmeans(cleanedDataset[1:1,], 3)
View(cleanedDataset)
View(cleanedDataset)
View(cleanedDataset)
library(classInt)
rm(list=ls())
options(scipen=99999)
# Setting working directory dynamically
tryCatch({
setwd(getSrcDirectory()[1])
}, error = function (e) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
})
# Loading dataset
dataset <- read.csv("./dataset/SalesData.csv", na.strings = c("", " ", "\"\"", "?", "??", "???", "!"), stringsAsFactors = T)
str(dataset)
summary(dataset)
# #############
# Data Cleaning
#
# Step 1 - Removal of irrelevant data
# Step 2 - Deduplicate / Aggregate data
# Step 3 - Fix structural errors
# Step 4 - Deal with missing data
# Step 5 - Filter out data outliers
# Step 6 -  Validate data
#
# NA values for Region identified using Summary
Summary(dataset$Region)
# Remove NA's from Region column
dataset$Region <- as.character(dataset$Region)
dataset$Region[is.na(dataset$Region)] <- "Unknown"
dataset$Region <- factor(dataset$Region)
# NA values for ItemType identified using Summary
Summary(dataset$ItemType)
# Remove NA's from ItemType column
dataset$ItemType <- as.character(dataset$ItemType)
dataset$ItemType[is.na(dataset$ItemType)] <- "Unknown"
dataset$ItemType <- factor(dataset$ItemType)
# NA values for Sales.Channel identified using Summary
Summary(dataset$Sales.Channel)
# Remove NA's and irrelevant values from SalesChannel column
dataset$Sales.Channel <- as.character(dataset$Sales.Channel)
dataset$Sales.Channel[is.na(dataset$Sales.Channel)] <- "Unknown"
dataset$Sales.Channel[dataset$Sales.Channel != "Online" & dataset$Sales.Channel != "Offline"] <- "Unknown"
dataset$Sales.Channel <- factor(dataset$Sales.Channel)
levels(dataset$Sales.Channel)
dataset$Order.Date <- as.Date(dataset$Order.Date, format = "%m/%d/%Y")
dataset$Ship.Date <- as.Date(dataset$Ship.Date, format = "%m/%d/%Y")
dataset$Unit.Price <- ((dataset$Unit.Price - min(dataset$Unit.Price))/(max(dataset$Unit.Price) - min(dataset$Unit.Price))) * (10-1) + 1
# Discretization of Quantity (also addresses outliers)
#
# Key:
# L  -> Low
# M  -> Medium
# H  -> High
#
bins <- classIntervals(dataset$Units.Sold, 3, style = 'equal')
unitsSoldType = c()
for (i in 1:length(dataset$Units.Sold)) {
rating = "L"
if(dataset$Units.Sold[i] > bins$brks[2] && dataset$Units.Sold[i] <= bins$brks[3]){
rating = "M"
}
if(dataset$Units.Sold[i] > bins$brks[3]){
rating = "H"
}
unitsSoldType <- append(unitsSoldType, rating)
}
dataset$Units.Sold.Type <- as.factor(unitsSoldType)
# Inspect new categorical column
summary(dataset$Units.Sold.Type)
str(dataset$Unit.Price)
hist(dataset$Unit.Price)
# Plot density graph...
plot(density(dataset$Unit.Price, na.rm = T))
# Write cleaned dataset to file
write.csv(dataset, "./output/sales-data_cleaned.csv", row.names = F)
############# DATA CLEANING COMPLETE #############
# Inspect cleaned dataset
View(dataset)
cleanedDataset <- read.csv("./output/sales-data_cleaned.csv", stringsAsFactors = T)
# <------------------ Problem 01 ------------------>
# Problem 01a - Apply binning and normalization as necessary to improve results.
# Completed in data cleaning and preparation process above
# Problem 01b - Construct new field which has the number of days between order Date and Ship Date.
deliveryDays <- c()
for (i in 1:length(cleanedDataset$Order.Date)) {
shippingDays <- as.Date(cleanedDataset$Ship.Date[i]) - as.Date(cleanedDataset$Order.Date[i])
deliveryDays <- append(deliveryDays, as.integer(strtoi(shippingDays, base = 0L)))
}
# Assigning to new column called "Ship Time"
cleanedDataset$Ship.Time <- deliveryDays
# Problem 01c - Provide short in-code comments to explain the reason and what choices are made.
# <------------------ End of Problem 01 ------------------>
# Check dataset to confirm changes above
View(cleanedDataset)
View(cleanedDataset)
# Convert factors to numeric for clustering
cleanedDataset <- dplyr::mutate_all(cleanedDataset, function(x) as.numeric(x))
View(cleanedDataset)
cleanedDataset$Order.ID <- NULL
View(cleanedDataset)
kmeans(cleanedDataset[1:1,], 3)
kmeans(cleanedDataset[1:200,], 3)
sample.salesdata <- cleanedDataset[1:200,]
str(sample.salesdata)
dis.matrix <- dist(sample.salesdata)
hclust.01 <- hclust(dis.matrix, method = "average")
plot(hclust.01)
# 4 cluster :
cluster.members.four <- cutree(hclust.01, 4)
View(as.data.frame(cluster.members.four))
plot(cluster.members.four)
aggregate(sample.salesdata, by=list(cluster.members.four), FUN = mean)
# 4 cluster :
km.results.four <- kmeans(sample.salesdata, 4)
km.results.four
plot(sample.salesdata, km.results.four$cluster)
# 6 cluster :
km.results.six <- kmeans(sample.salesdata, 6)
km.results.six
plot(sample.salesdata, km.results.six$cluster)
# 8 cluster :
km.results.eight <- kmeans(sample.salesdata, 8)
km.results.eight
plot(sample.salesdata, km.results.eight$cluster)
?apriori
# install.packages("pacman")
# Load packages, install if unavailable
pacman::p_load(
"arules",
# "arulesViz",
"zeallot",
"backports",
"classInt",
"dplyr",
"chron"
)
rm(list=ls())
options(scipen=99999)
# Setting working directory dynamically
tryCatch({
setwd(getSrcDirectory()[1])
}, error = function (e) {
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
})
# Loading dataset
dataset <- read.csv("./dataset/OnlineRetail.csv", na.strings = c("", " ", "\"\"", "?", "??", "???", "!"), stringsAsFactors = T)
str(dataset)
summary(dataset)
# #############
# Data Cleaning
#
# Step 1 - Removal of irrelevant data
# Step 2 - Deduplicate / Aggregate your data
# Step 3 - Fix structural errors
# Step 4 - Deal with missing data
# Step 5 - Filter out data outliers
# Step 6 -  Validate your data
#
# Removing irrelevant data (noise removal)
dataset <- filter(dataset, Country == "Switzerland")
# Checking and removal for meaningless descriptions
emptyDescriptions <- dataset[nchar(as.character(dataset$Description)) <= 5, "Description"]
emptyDescriptions
length(emptyDescriptions)
dataset <- filter(dataset, nchar(as.character(dataset$Description)) > 5)
# Fixing items with a negative quantity and unit price
dataset$Quantity <- abs(dataset$Quantity)
dataset$UnitPrice <- abs(dataset$UnitPrice)
summary(dataset)
# Outliers itemtified with unit price
summary(dataset$UnitPrice)
# Outlier Removal
q1UnitPrice <- summary(dataset$UnitPrice)[2]
q3UnitPrice <- summary(dataset$UnitPrice)[5]
IQR <- q3UnitPrice - q1UnitPrice
dataset <- dataset[dataset$UnitPrice >= q1UnitPrice - 1.5*IQR & dataset$UnitPrice <= q3UnitPrice + 1.5*IQR, ]
# Discretization of Quantity (also addresses outliers)
#
# Key:
# L  -> Low       -> range 0 to 5
# M  -> Medium    -> range 6 to 10
# H  -> High      -> range 11 to 15
# VH -> Very High -> range 16 and up
#
dataset$Quantity <- cut(dataset$Quantity, c(0,5,10,15,max(dataset$Quantity)), right = TRUE, labels = c("L","M","H","VH"))
summary(dataset$Quantity)
# Normalization of UnitPrice
dataset$UnitPrice <- ((dataset$UnitPrice - min(dataset$UnitPrice))/(max(dataset$UnitPrice) - min(dataset$UnitPrice))) * (10-1) + 1
# replacement of unwanted characters
dataset$Description <- trimws(dataset$Description)
# replace all spaces with underscores in description
dataset$Description <- gsub(" ", "_", dataset$Description)
# Removing free items
dataset <- filter(dataset, UnitPrice > 0)
# replace "C" spaces with nothing in InvoiceNo
dataset$InvoiceNo <- gsub("C", "", dataset$InvoiceNo)
# cleaning date field (separation of date and time)
invoiceTimes <- c()
invoiceDates <- c()
for(i in 1:length(dataset$InvoiceDate)){
splittedDate <- strsplit(toString(dataset$InvoiceDate[i]), " ")
invoiceDate <- splittedDate[[1]][1]
# Seconds are needed in order to convert string to chron objects
invoiceTime <- paste(splittedDate[[1]][2], ":00", sep="")
invoiceTimes <- append(invoiceTimes, invoiceTime)
invoiceDates <- append(invoiceDates, invoiceDate)
}
# Override invoice dates with standardized format
dataset$InvoiceDate <- invoiceDates
# converting dates to native r dates using chron
invoiceDates <- as.Date(dataset$InvoiceDate, format = "%m/%d/%Y")
# creating cron objects
chronDateValues <- chron(date=as.character(invoiceDates), times=invoiceTimes, format=c(dates="Y-m-d", times="h:m:s"))
# Add chron dates as new column after "InvoiceDate" column
dataset <- tibble::add_column(dataset, ChronDates = chronDateValues, .after = "InvoiceDate")
# Output cleaned dataset to file
write.csv(dataset, "./output/switzerland-retail-data_cleaned.csv", row.names = F)
############# DATA CLEANING COMPLETE #############
# View cleaned dataset
View(dataset)
# Association Rules
# <------------------ Problem 02 ------------------>
# Goal:
# to identify the settings for Minimum Support and Confidence
# and present the extracted association rules for best performing associations
# Loading in cleaned dataset
switzerlandRetailData <- read.transactions("./output/switzerland-retail-data_cleaned.csv", format=c("single"), header = TRUE, rm.duplicates = FALSE, cols = c("InvoiceNo", "StockCode"), sep=",")
# Viewing the item frequencies
itemFrequencyPlot(switzerlandRetailData, support=0.1)
itemFrequencyPlot(switzerlandRetailData, topN=4)
drules <- apriori(switzerlandRetailData)
summary(drules)
inspect(drules)
View(as(drules, "data.frame"))
apriori(switzerlandRetailData, parameter = list(support=0.2, confidence=0.75, minlen=2, maxlen=4))
drules2 <- apriori(switzerlandRetailData, parameter = list(support=0.2, confidence=0.75, minlen=2, maxlen=4))
summary(drules2)
summary(drules2)
summary(drules)
drules2 <- apriori(switzerlandRetailData, parameter = list(support=0.1, confidence=0.8, minlen=2, maxlen=4))
summary(drules2)
plot(drules2)
# Load packages, install if unavailable
pacman::p_load(
"arules",
"arulesViz",
"zeallot",
"backports",
"classInt",
"dplyr",
"chron"
)
tinytex::install_tinytex()
